{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Targeted_Dropout.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnlqjRLeRI2S",
        "colab_type": "code",
        "outputId": "022c9c70-6e7c-41d6-f2f8-6d2c1d5fe424",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "!pip3 install torch torchvision"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.16.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXkY1ZWNRI4f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oK5gwxtjRI6v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60sI0HEjSMYX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "lr = 3e-4\n",
        "drop_rate = 0.8\n",
        "targ_per = 0.8\n",
        "num_epochs = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0XODigcR18c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST('../data', train=True, download=True,\n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize((0.1307,), (0.3081,))\n",
        "                       ])),\n",
        "        batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize((0.1307,), (0.3081,))\n",
        "                       ])),\n",
        "        batch_size=batch_size, shuffle=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_s45QX2cZoT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, drop_rate, targ_perc):\n",
        "        super(Net, self).__init__()\n",
        "        self.module_list = nn.ModuleList([nn.Linear(input_size, hidden_size)\n",
        "                                          if i == 0 else nn.Linear(hidden_size, hidden_size) for i in range(2)])\n",
        "        self.logit_layer = nn.Linear(hidden_size, 10)\n",
        "        self.drop_rate = drop_rate\n",
        "        self.targ_perc = targ_perc\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        for layer in self.module_list:\n",
        "            weight = self.targeted_weight_dropout(layer.weight,\n",
        "                                                  self.drop_rate,\n",
        "                                                  self.targ_perc,\n",
        "                                                  is_training=True)\n",
        "            inputs = F.relu(F.linear(inputs, weight, layer.bias))\n",
        "        logits = self.logit_layer(inputs)\n",
        "\n",
        "        return logits\n",
        "\n",
        "    @staticmethod\n",
        "    def targeted_weight_dropout(weight, drop_rate, targ_perc, is_training):\n",
        "        weight_size = list(weight.size())\n",
        "        norm = torch.abs(weight)\n",
        "        idx = int(targ_perc * float(weight_size[0]))\n",
        "        threshold = torch.sort(norm, dim=0)[0][idx]\n",
        "        mask = (norm < threshold).to(weight.device)\n",
        "\n",
        "        if not is_training:\n",
        "            weight = (1.0 - mask).float() * weight\n",
        "            return weight\n",
        "\n",
        "        dropout_mask = (torch.rand(weight_size) < drop_rate)\n",
        "        dropout_mask = dropout_mask.to(weight.device)\n",
        "        mask = (dropout_mask * mask).float()\n",
        "        weight = (1.0 - mask) * weight\n",
        "        return weight\n",
        "\n",
        "    def prune_weights(self):\n",
        "        for layer in self.module_list:\n",
        "            weight = layer.weight\n",
        "            pruned_weight = self.targeted_weight_dropout(weight,\n",
        "                                                         self.drop_rate,\n",
        "                                                         self.targ_perc,\n",
        "                                                         is_training=False)\n",
        "            layer.weight = nn.Parameter(pruned_weight)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9ZE22-GX_xb",
        "colab_type": "text"
      },
      "source": [
        "**Pruning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dexI_tJGbM_Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "d04b795f-6e05-4ace-8e03-d3041ebe97fa"
      },
      "source": [
        "net = Net(784, 100, drop_rate, targ_per).to(device)\n",
        "opt = torch.optim.Adam(net.parameters(), lr)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    for i, (train_x, train_y) in enumerate(train_loader):\n",
        "        train_x = train_x.to(device).view(-1, 784)\n",
        "        train_y = train_y.to(device)\n",
        "        preds = net(train_x)\n",
        "        loss = criterion(preds, train_y)\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(\"Train epoch:[{}/{}] loss :{:.4f}\".format(epoch, num_epochs, loss))\n",
        "\n",
        "# after training is done, prune(make sparse) weights\n",
        "net.prune_weights()\n",
        "\n",
        "with torch.no_grad():\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for test_x, test_y in test_loader:\n",
        "        test_x = test_x.view(-1, 784).to(device)\n",
        "        test_y = test_y.to(device)\n",
        "        logits = net(test_x)\n",
        "        preds = torch.argmax(logits, 1)\n",
        "        correct += (preds == test_y).sum().item()\n",
        "        total += test_y.size(0)\n",
        "    print(\"accuracy : {:.2f}\".format(correct / total * 100))\n",
        "    num_zeros = 0\n",
        "    for layer in net.module_list:\n",
        "        num_zeros += (layer.weight == 0.0).sum().item()\n",
        "    print(\"number of zero weights: \", num_zeros)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train epoch:[1/3] loss :0.9202\n",
            "Train epoch:[1/3] loss :0.4517\n",
            "Train epoch:[1/3] loss :0.3398\n",
            "Train epoch:[1/3] loss :0.3029\n",
            "Train epoch:[2/3] loss :0.3967\n",
            "Train epoch:[2/3] loss :0.3733\n",
            "Train epoch:[2/3] loss :0.2724\n",
            "Train epoch:[2/3] loss :0.2756\n",
            "Train epoch:[3/3] loss :0.2495\n",
            "Train epoch:[3/3] loss :0.2526\n",
            "Train epoch:[3/3] loss :0.2604\n",
            "Train epoch:[3/3] loss :0.1744\n",
            "accuracy : 93.62\n",
            "number of zero weights:  70720\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mt7rMq3EZ-Sy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXlIiPOtXrhs",
        "colab_type": "text"
      },
      "source": [
        "**No pruning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMh8oCR-Z__q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VanillaNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, drop_rate, targ_perc):\n",
        "        super(VanillaNet, self).__init__()\n",
        "        self.module_list = nn.ModuleList([nn.Linear(input_size, hidden_size)\n",
        "                                          if i == 0 else nn.Linear(hidden_size, hidden_size) for i in range(2)])\n",
        "        self.logit_layer = nn.Linear(hidden_size, 10)\n",
        "        self.drop_rate = drop_rate\n",
        "        self.targ_perc = targ_perc\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        for layer in self.module_list:\n",
        "            inputs = F.relu(layer(inputs))            \n",
        "        logits = self.logit_layer(inputs)\n",
        "\n",
        "        return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNS0fyjoXwyD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "4782c678-0999-495c-bd86-1a6011fe17e6"
      },
      "source": [
        "vanilla_net = VanillaNet(784, 100, drop_rate=0.0, targ_perc=0.0).to(device)\n",
        "opt2 = torch.optim.Adam(vanilla_net.parameters(), lr)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    for i, (train_x, train_y) in enumerate(train_loader):\n",
        "        train_x = train_x.to(device).view(-1, 784)\n",
        "        train_y = train_y.to(device)\n",
        "        preds = vanilla_net(train_x)\n",
        "        loss = criterion(preds, train_y)\n",
        "        opt2.zero_grad()\n",
        "        loss.backward()\n",
        "        opt2.step()\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(\"Train epoch:[{}/{}] loss :{:.4f}\".format(epoch, num_epochs, loss))\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for test_x, test_y in test_loader:\n",
        "        test_x = test_x.view(-1, 784).to(device)\n",
        "        test_y = test_y.to(device)\n",
        "        logits = vanilla_net(test_x)\n",
        "        preds = torch.argmax(logits, 1)\n",
        "        correct += (preds == test_y).sum().item()\n",
        "        total += test_y.size(0)\n",
        "    print(\"accuracy : {:.2f}\".format(correct / total * 100))\n",
        "    num_zeros = 0\n",
        "    for layer in vanilla_net.module_list:\n",
        "        num_zeros += (layer.weight == 0.0).sum().item()\n",
        "    print(\"number of zero weights: \", num_zeros)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train epoch:[1/3] loss :0.5412\n",
            "Train epoch:[1/3] loss :0.4184\n",
            "Train epoch:[1/3] loss :0.3136\n",
            "Train epoch:[1/3] loss :0.2389\n",
            "Train epoch:[2/3] loss :0.1732\n",
            "Train epoch:[2/3] loss :0.1569\n",
            "Train epoch:[2/3] loss :0.2125\n",
            "Train epoch:[2/3] loss :0.1876\n",
            "Train epoch:[3/3] loss :0.1348\n",
            "Train epoch:[3/3] loss :0.1060\n",
            "Train epoch:[3/3] loss :0.1090\n",
            "Train epoch:[3/3] loss :0.2332\n",
            "accuracy : 95.72\n",
            "number of zero weights:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x500Ge1GZ8aK",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}